

exp_name: LM
# 训练／实验相关配置
optimizer:
  type: AdamW                     # 优化器类型
  beta1: 0.9                      # 一阶动量系数
  beta2: 0.999                    # 二阶动量系数
  eps: 0.00000001                 # 防止除零的epsilon
  weight_decay: 0.01              # 权重衰减系数


epochs: 2                       # 训练轮数
batch_size: 96                    # 批次大小


learning_rate: 0.0001             # 初始学习率
warmup_steps: 1000                # 学习率 warm-up 步数
train_ids_path: /home/niu/code/cs336/assignment1-basics/data/train_ids/TinyStoriesV2-GPT4_train_ids.npy # 训练数据集路径
device: cuda                     # 设备 


# 梯度裁剪
max_norm: 1.0

# 学习率调度器相关配置
warmup_steps: 2000  #学习率warm-up步数
cosine_cycle_steps: 8000  #学习率cosine cycle步数
learning_rate_min: 0.00001  #学习率最小值



# 模型保存和打印
save_path: ./models_checkpoints/  # 模型保存路径
epoch_print_freq: 1                    # 打印频率
iter_print_freq: 10                    # 打印频率


# 训练由于意外中断，这里设置resume的相关参数
resume_from_checkpoint: True
checkpoint_path: /home/niu/code/cs336/assignment1-basics/cs336_basics/train/LM/models_checkpoints/iter_4150/model_iter_4150.pth


